{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"/Users/anand/Downloads/WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the null values #no null values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking datatype\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping column employee number as it is not needed for any analysis\n",
    "df.drop(columns=[\"EmployeeNumber\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Over18\"].unique()\n",
    "#this columnn has only one value which is Y ,so dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Over18\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"EmployeeCount\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"StandardHours\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping EmployeeCount column\n",
    "df.drop(columns=[\"EmployeeCount\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"StandardHours\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of attrition\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "sn.countplot(x=\"Attrition\",data=df)\n",
    "plt.show()\n",
    "#Imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age of employees who is leaving and who are staying\n",
    "sn.barplot(x=\"Attrition\",y=\"Age\",data=df)\n",
    "plt.show()\n",
    "#below graph shows that people who are staying has age more than 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of employees based on buisness travel\n",
    "sn.countplot(x=\"BusinessTravel\",data=df)\n",
    "plt.show()\n",
    "#most of the employee travel rarely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of each category of buisness travel where attrition is true\n",
    "sn.countplot(x=\"BusinessTravel\",data=df,hue=\"Attrition\")\n",
    "plt.show()\n",
    "# proportion of attrition is higher where travel is frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#which department attrintion is high\n",
    "sn.countplot(x=\"Department\",data=df,hue=\"Attrition\")\n",
    "plt.show()\n",
    "#sales 1:4 ,R&D 1:9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when distance from home is above 15 kms whats the attrition\n",
    "sn.countplot(x=\"Attrition\",data=df.loc[df[\"DistanceFromHome\"]>15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attrition in each job role\n",
    "plt.figure(figsize=(22,6))\n",
    "sn.countplot(x=\"JobRole\",data=df,hue=\"Attrition\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attrition ratio based on gender\n",
    "sn.countplot(x=\"Gender\",data=df,hue=\"Attrition\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attrition ratio based on job satisfaction\n",
    "sn.countplot(x=\"JobSatisfaction\",data=df,hue=\"Attrition\")\n",
    "plt.show()\n",
    "# as job satisfaction increases proportion of attrition decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attrition ratio in MaritalStatus\n",
    "sn.countplot(x=\"MaritalStatus\",data=df,hue=\"Attrition\")\n",
    "plt.show()\n",
    "#in singles ratio is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attrition based on overtime\n",
    "sn.countplot(x=\"OverTime\",data=df,hue=\"Attrition\")\n",
    "plt.show()\n",
    "#more overtime more attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x=\"YearsWithCurrManager\",data=df.loc[df[\"Attrition\"]==\"Yes\"])\n",
    "plt.show()\n",
    "#if years working wth current manager is 0 then attrition was very high .Also after 2 years and at 7 years of working ,more ppl left\n",
    "#which means in  new project they moved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work life balance with attrition\n",
    "sn.countplot(x=\"WorkLifeBalance\",data=df.loc[df[\"Attrition\"]==\"Yes\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average working years of the employees\n",
    "sn.barplot(x=\"Attrition\",y=\"YearsAtCompany\",data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attritionand years since last promotion\n",
    "df.loc[df[\"Attrition\"]==\"Yes\"].groupby([\"YearsSinceLastPromotion\"]).agg({\"Attrition\":\"count\"})\n",
    "\n",
    "#promotion is not the factor why people left the company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performnce rating and attrition\n",
    "sn.countplot(x=\"PerformanceRating\",data=df.loc[df[\"Attrition\"]==\"Yes\"])\n",
    "plt.show()\n",
    "# people who left were who got rating 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKEWNESS\n",
    "print(df.skew())\n",
    "print(\"Total count of numeric features: \",len(df.skew()))\n",
    "print(\"count of features which are significantly skewed: \",len(df.skew().loc[abs(df.skew())>0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seprate the input and output \n",
    "X=df.drop(columns=[\"Attrition\"])\n",
    "y=df[[\"Attrition\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELEIMINATING SKEWNWSS\n",
    "import numpy as np\n",
    "for index in X.skew().index:\n",
    "    if X.skew().loc[index]>0.5:\n",
    "        X[index]=np.log1p(X[index])\n",
    "    if X.skew().loc[index]<-0.5:\n",
    "        X[index]=np.square(X[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness\n",
    "print(X.skew())\n",
    "print(\"Total count of numeric features: \",len(X.skew()))\n",
    "print(\"count of features which are significantly skewed: \",len(X.skew().loc[abs(X.skew())>0.5]))\n",
    "#skewness changed from 14 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the number of columns of object datatype\n",
    "print(X.dtypes.loc[X.dtypes==\"object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to convert above columns to 1 and 0 using pd.get_dummies\n",
    "X=pd.get_dummies(X,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(X)\n",
    "X_new=sc.transform(X)\n",
    "X_new=pd.DataFrame(X_new,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelencoder to convert target class into integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "ls=LabelEncoder()\n",
    "ls.fit(y)\n",
    "y=ls.transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imbalanced dataset so we will focus on auc-roc score\n",
    "#!pip install imblearn\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def max_aucroc_score(clf,X,y):\n",
    "    max_aucroc_score=0\n",
    "    for r_state in range(42,100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, y,random_state = r_state,test_size=0.20,stratify=y)\n",
    "        x_train, y_train = SMOTE().fit_sample(x_train, y_train)\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        aucroc_scr=roc_auc_score(y_test,y_pred)\n",
    "        print(\"auc roc score corresponding to \",r_state,\" is \",aucroc_scr)\n",
    "        if aucroc_scr>max_aucroc_score:\n",
    "            max_aucroc_score=aucroc_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max auc roc score corresponding to \",final_r_state,\" is \",max_aucroc_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets use logistic regression and check\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "lg_clf=LogisticRegression()\n",
    "max_aucroc_score(lg_clf,X_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Mean roc auc score for logistic classifier: \",cross_val_score(lg_clf,X_new,y,cv=5,scoring=\"roc_auc\").mean())\n",
    "print(\"standard deviation in roc auc score for logistic classifier: \",cross_val_score(lg_clf,X_new,y,cv=5,scoring=\"roc_auc\").std())\n",
    "print(cross_val_score(lg_clf,X_new,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets chcek decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc=DecisionTreeClassifier()\n",
    "max_aucroc_score(dc,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean auc roc score for decision tree classifier: \",cross_val_score(dc,X,y,cv=5,scoring=\"roc_auc\").mean())\n",
    "print(\"standard deviation in auc roc score for decision tree classifier: \",cross_val_score(dc,X,y,cv=5,scoring=\"roc_auc\").std())\n",
    "print(cross_val_score(dc,X,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={\"n_estimators\":[10,100,500]}\n",
    "rf_clf=RandomForestClassifier()\n",
    "clf = GridSearchCV(rf_clf, parameters, cv=5,scoring=\"roc_auc\")\n",
    "clf.fit(X,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf=RandomForestClassifier(n_estimators=500)\n",
    "max_aucroc_score(rf_clf,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_val_score\n",
    "print(\"Mean auc roc score for random forest classifier: \",cross_val_score(rf_clf,X,y,cv=5,scoring=\"roc_auc\").mean())\n",
    "print(\"standard deviation in auc roc score for random forest classifier: \",cross_val_score(rf_clf,X,y,cv=5,scoring=\"roc_auc\").std())\n",
    "print(cross_val_score(rf_clf,X,y,cv=5,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "#For KNN we need to know the best value of k using grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "kc=KNeighborsClassifier()\n",
    "neighbors={\"n_neighbors\":range(1,30)}\n",
    "clf = GridSearchCV(kc, neighbors, cv=5,scoring=\"roc_auc\")\n",
    "clf.fit(X_new,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc=KNeighborsClassifier(n_neighbors=28)\n",
    "max_aucroc_score(kc,X_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "parameters={\"kernel\":[\"linear\", \"poly\", \"rbf\"],\"C\":[0.001,0.01,0.1,1,10]}\n",
    "clf = GridSearchCV(svc, parameters, cv=5,scoring=\"roc_auc\")\n",
    "clf.fit(X_new,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(kernel=\"linear\",C=0.1)\n",
    "max_aucroc_score(svc,X_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "parameters={\"learning_rate\":[0.001,0.01,0.1,1],\"n_estimators\":[10,100,500,1000]}\n",
    "gb_clf=GradientBoostingClassifier()\n",
    "clf = GridSearchCV(gb_clf, parameters, cv=5,scoring=\"roc_auc\")\n",
    "clf.fit(X,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf=GradientBoostingClassifier(learning_rate=0.1,n_estimators=500)\n",
    "max_aucroc_score(gb_clf,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final modelsvc \n",
    "x_train, x_test, y_train, y_test = train_test_split(X_new, y,random_state = 70,test_size=0.20,stratify=y)\n",
    "x_train, y_train = SMOTE().fit_sample(x_train, y_train)\n",
    "svc=SVC(kernel=\"linear\",C=0.1)\n",
    "svc.fit(x_train,y_train)\n",
    "y_pred=svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"f1 score is : \",f1_score(y_test,y_pred))\n",
    "print(\"classification report \\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC ROC Score: \",roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HR_Analytics.pkl']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(svc,\"HR_Analytics.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
